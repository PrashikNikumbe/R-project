---
title: "R Notebook"
output: html_notebook
---
```{r}

```

This is an [R Markdown](http://rmarkdown.rstudio.com) Notebook. When you execute code within the notebook, the results appear beneath the code. 

Try executing this chunk by clicking the *Run* button within the chunk or by placing your cursor inside it and pressing *Ctrl+Shift+Enter*. 

```{r}
#Installing Package

install.packages("dplyr")
install.packages("data.table")
install.packages("ggplot2")
install.packages("caret")
install.packages("corrplot")
install.packages("xgboost")
install.packages("cowplot")
```


```{r}
install.packages("Metrics")
install.packages("hydroGOF")

```

Add a new chunk by clicking the *Insert Chunk* button on the toolbar or by pressing *Ctrl+Alt+I*.

When you save the notebook, an HTML file containing the code and output will be saved alongside it (click the *Preview* button or press *Ctrl+Shift+K* to preview the HTML file).

The preview shows you a rendered HTML copy of the contents of the editor. Consequently, unlike *Knit*, *Preview* does not run any R code chunks. Instead, the output of the chunk when it was last run in the editor is displayed.
```{r}
#Loading Packages

library(data.table) # used for reading and manipulation of data
library(dplyr)      # used for data manipulation and joining
library(ggplot2)    # used for ploting 
library(caret)      # used for modeling
library(corrplot)   # used for making correlation plot
library(xgboost)    # used for building XGBoost model
library(cowplot)    # used for combining multiple plots
```


```{r}
#Reading data

data =  read_csv("C:\\Users\\Dell\\Downloads\\R lab\\R lab\\Sales data.csv")
nrow(data)
```


```{r}
summary(data)



```

```{r}
#Exploratory Data Analysis(EDA)

#Dependent Variable

ggplot(data) + geom_histogram(aes(data$Item_Outlet_Sales), binwidth = 100, fill = "darkgreen") +
  xlab("Item_Outlet_Sales")

```
```{r}
#Independent Variables(numeric variables)

p1 = ggplot(data) + geom_histogram(aes(Item_Weight), binwidth = 0.5, fill = "blue")
p2 = ggplot(data) + geom_histogram(aes(Item_Visibility), binwidth = 0.005, fill = "blue")
p3 = ggplot(data) + geom_histogram(aes(Item_MRP), binwidth = 1, fill = "blue")
plot_grid(p1, p2, p3, nrow = 1) # plot_grid() from cowplot package
```

```{r}
#Independent Variables(categorical variables)

ggplot(data %>% group_by(Item_Fat_Content) %>% summarise(Count = n())) + 
  geom_bar(aes(Item_Fat_Content, Count), stat = "identity", fill = "coral1")
```
```{r}
#Correcting Values

data$Item_Fat_Content[data$Item_Fat_Content == "LF"] = "Low Fat"
data$Item_Fat_Content[data$Item_Fat_Content == "low fat"] = "Low Fat"
data$Item_Fat_Content[data$Item_Fat_Content == "reg"] = "Regular"
ggplot(data %>% group_by(Item_Fat_Content) %>% summarise(Count = n())) + 
  geom_bar(aes(Item_Fat_Content, Count), stat = "identity", fill = "coral1")
```
```{r}
#check the other categorical variables

# plot for Item_Type
p4 = ggplot(data %>% group_by(Item_Type) %>% summarise(Count = n())) + 
  geom_bar(aes(Item_Type, Count), stat = "identity", fill = "coral1") +
  xlab("") +
  geom_label(aes(Item_Type, Count, label = Count), vjust = 0.5) +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))+
  ggtitle("Item_Type")

# plot for Outlet_Identifier
p5 = ggplot(data %>% group_by(Outlet_Identifier) %>% summarise(Count = n())) + 
  geom_bar(aes(Outlet_Identifier, Count), stat = "identity", fill = "coral1") +
  geom_label(aes(Outlet_Identifier, Count, label = Count), vjust = 0.5) +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

# plot for Outlet_Size
p6 = ggplot(data %>% group_by(Outlet_Size) %>% summarise(Count = n())) + 
  geom_bar(aes(Outlet_Size, Count), stat = "identity", fill = "coral1") +
  geom_label(aes(Outlet_Size, Count, label = Count), vjust = 0.5) +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

second_row = plot_grid(p5, p6, nrow = 1)
plot_grid(p4, second_row, ncol = 1)


```
```{r}
#remaining categorical variables
# plot for Outlet_Establishment_Year
p7 = ggplot(data %>% group_by(Outlet_Establishment_Year) %>% summarise(Count = n())) + 
  geom_bar(aes(factor(Outlet_Establishment_Year), Count), stat = "identity", fill = "coral1") +
  geom_label(aes(factor(Outlet_Establishment_Year), Count, label = Count), vjust = 0.5) +
  xlab("Outlet_Establishment_Year") +
  theme(axis.text.x = element_text(size = 8.5))
# plot for Outlet_Type
p8 = ggplot(data %>% group_by(Outlet_Type) %>% summarise(Count = n())) + 
  geom_bar(aes(Outlet_Type, Count), stat = "identity", fill = "coral1") +
  geom_label(aes(factor(Outlet_Type), Count, label = Count), vjust = 0.5) +
  theme(axis.text.x = element_text(size = 8.5))

# ploting both plots together
plot_grid(p7, p8, ncol = 2)
```
```{r}
#Bivariate Analysis
#we'll explore the independent variables with respect to the target variable

#Target Variable vs Independent Numerical Variables
# Item_Weight vs Item_Outlet_Sales
p9 = ggplot(data) + 
  geom_point(aes(Item_Weight, Item_Outlet_Sales), colour = "violet", alpha = 0.3) +
  theme(axis.title = element_text(size = 8.5))

# Item_Visibility vs Item_Outlet_Sales
p10 = ggplot(data) + 
  geom_point(aes(Item_Visibility, Item_Outlet_Sales), colour = "violet", alpha = 0.3) +
  theme(axis.title = element_text(size = 8.5))

# Item_MRP vs Item_Outlet_Sales
p11 = ggplot(data) + 
  geom_point(aes(Item_MRP, Item_Outlet_Sales), colour = "violet", alpha = 0.3) +
  theme(axis.title = element_text(size = 8.5))
second_row_2 = plot_grid(p10, p11, ncol = 2)
plot_grid(p9, second_row_2, nrow = 2)
```
```{r}
#Target Variable vs Independent Categorical Variables

# Item_Type vs Item_Outlet_Sales
p12 = ggplot(data) + 
  geom_violin(aes(Item_Type, Item_Outlet_Sales), fill = "magenta") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1),
        axis.text = element_text(size = 6),
        axis.title = element_text(size = 8.5))

# Item_Fat_Content vs Item_Outlet_Sales
p13 = ggplot(data) + 
  geom_violin(aes(Item_Fat_Content, Item_Outlet_Sales), fill = "magenta") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1),
        axis.text = element_text(size = 8),
        axis.title = element_text(size = 8.5))

# Outlet_Identifier vs Item_Outlet_Sales
p14 = ggplot(data) + 
  geom_violin(aes(Outlet_Identifier, Item_Outlet_Sales), fill = "magenta") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1),
        axis.text = element_text(size = 8),
        axis.title = element_text(size = 8.5))
second_row_3 = plot_grid(p13, p14, ncol = 2)
plot_grid(p12, second_row_3, ncol = 1)
```
```{r}
#remaining variables

p15 = ggplot(data) + geom_violin(aes(Outlet_Location_Type, Item_Outlet_Sales), fill = "magenta")
p16 = ggplot(data) + geom_violin(aes(Outlet_Type, Item_Outlet_Sales), fill = "magenta")
plot_grid(p15, p16, ncol = 1)
```

```{r}
#Missing Value Treatment

#There are different methods to treat missing values based on the problem and the data. Some of the common techniques are as follows:
  
#1.Deletion of rows: In train dataset, observations having missing values in any variable are deleted. The downside of this method is the loss of information and drop in prediction power of model.

#2.Mean/Median/Mode Imputation: In case of continuous variable, missing values can be replaced with mean or median of all known values of that variable. For categorical variables, we can use mode of the given values to replace the missing values.

#3.Building Prediction Model: We can even make a predictive model to impute missing data in a variable. Here we will treat the variable having missing data as the target variable and the other variables as predictors. We will divide our data into 2 datasets-one without any missing value for that variable and the other with missing values for that variable. The former set would be used as training set to build the predictive model and it would then be applied to the latter set to predict the missing values.

#find missing values in a variable.

sum(is.na(data$Item_Weight))

#Imputing Missing Value

missing_index = which(is.na(data$Item_Weight))
for(i in missing_index){
  
  item = data$Item_Identifier[i]
  data$Item_Weight[i] = mean(data$Item_Weight[data$Item_Identifier == item], na.rm = T)
}

#Cross Check

sum(is.na(data$Item_Weight))

#Replacing 0's in Item_Visibility variable

ggplot(data) + geom_histogram(aes(Item_Visibility), bins = 100)

#replace the zeroes

zero_index = which(data$Item_Visibility == 0)
for(i in zero_index){
  
  item = data$Item_Identifier[i]
  data$Item_Visibility[i] = mean(data$Item_Visibility[data$Item_Identifier == item], na.rm = T)
  
}

ggplot(data) + geom_histogram(aes(Item_Visibility), bins = 100)
```

```{r}
#Feature Engineering

#will create the following new features:
  
#1Item_Type_new: Broader categories for the variable Item_Type.
#2Item_category: Categorical variable derived from Item_Identifier.
#3Outlet_Years: Years of operation for outlets.
#4price_per_unit_wt: Item_MRP/Item_Weight
#5Item_MRP_clusters: Binned feature for Item_MRP.

#Item_Type variable and classify the categories into perishable and non_perishable as per our understanding and make it into a new feature.

#`:=` <- `<-`

setDT(data)


perishable = c("Breads", "Breakfast", "Dairy", "Fruits and Vegetables", "Meat", "Seafood")
non_perishable = c("Baking Goods", "Canned", "Frozen Foods", "Hard Drinks", "Health and Hygiene", "Household", "Soft Drinks")

# create a new feature 'Item_Type_new'
data[,Item_Type_new := ifelse(Item_Type %in% perishable, "perishable", ifelse(Item_Type %in% non_perishable, "non_perishable", "not_sure"))]

#Let's compare Item_Type with the first 2 characters of Item_Identifier, i.e., 'DR', 'FD', and 'NC'. These identifiers most probably stand for drinks, food, and non-consumable.


table(data$Item_Type, substr(data$Item_Identifier, 1, 2))

# Item_category Created

data[,Item_category := substr(data$Item_Identifier, 1, 2)]

#Outlet_Years (years of operation) and price_per_unit_wt (price per unit weight).

data$Item_Fat_Content[data$Item_category == "NC"] = "Non-Edible"

```
```{r}
```


```{r}
data[,Outlet_Size_num := ifelse(Outlet_Size == "Small", 0,
                                 ifelse(Outlet_Size == "Medium", 1, 2))]
data[,Outlet_Location_Type_num := ifelse(Outlet_Location_Type == "Tier 3", 0,
                                          ifelse(Outlet_Location_Type == "Tier 2", 1, 2))]
# removing categorical variables after label encoding
data[, c("Outlet_Size", "Outlet_Location_Type") := NULL]
```


```{r}
# years of operation for outlets
data[,Outlet_Years := 2013 - Outlet_Establishment_Year]
data$Outlet_Establishment_Year = as.factor(data$Outlet_Establishment_Year)

# Price per unit weight
data[,price_per_unit_wt := Item_MRP/Item_Weight]

# creating new independent variable - Item_MRP_clusters
data[,Item_MRP_clusters := ifelse(Item_MRP < 69, "1st", 
                                   ifelse(Item_MRP >= 69 & Item_MRP < 136, "2nd",
                                          ifelse(Item_MRP >= 136 & Item_MRP < 203, "3rd", "4th")))]



```


```{r}
#One hot encoding for the categorical variable

ohe = dummyVars("~.", data = data[,-c("Item_Identifier", "Outlet_Establishment_Year", "Item_Type")], fullRank = T)
ohe_df = data.table(predict(ohe, data[,-c("Item_Identifier", "Outlet_Establishment_Year", "Item_Type")]))
data = cbind(data[,"Item_Identifier"], ohe_df)

```


```{r}
data
data[,Item_Visibility := log(Item_Visibility + 1)] # log + 1 to avoid division by zero
data[,price_per_unit_wt := log(price_per_unit_wt + 1)]
```


```{r}
#Scaling numeric predictors

#Let's scale and center the numeric variables to make them have a mean of zero, standard deviation of one and scale of 0 to 1. Scaling and centering is required for linear regression models.

num_vars = which(sapply(data, is.numeric)) # index of numeric features
num_vars_names = names(num_vars)
data_numeric = data[,setdiff(num_vars_names, "Item_Outlet_Sales"), with = F]
prep_num = preProcess(data_numeric, method=c("center", "scale"))
data_numeric_norm = predict(prep_num, data_numeric)

data[,setdiff(num_vars_names, "Item_Outlet_Sales") := NULL] # removing numeric independent variables
data = cbind(data, data_numeric_norm)
```


```{r}
train = data[1:6392]
test = data[6393:nrow(data)]

```


```{r}
#Correlated Variables

cor_train = cor(train[,-c("Item_Identifier")])
corrplot(cor_train, method = "color",tl.cex=0.5)
```


```{r}
train = train[complete.cases(train), ]
summary(train$Item_Outlet_Sales)
```


```{r}
#Model Building


# Load the Metrics package 
library(Metrics)

#Linear Regression

#Building Model
setDT(train)
setDT(test)

linear_reg_mod = lm(Item_Outlet_Sales ~ ., data = train[,-c("Item_Identifier")])

#Making Predictions on test Data


linearprediction = predict(linear_reg_mod, test[,-c("Item_Identifier","Item_Outlet_Sales")])

actual = test$Item_Outlet_Sales
plot(linearprediction[1:50],type="o",col = "red", xlab = "Values", ylab = "Sales", 
   main = "Line chart")
lines(actual[1:50], type = "o", col = "blue")
rmse(actual, linearprediction)
```


```{r}
#Lasso Regression

set.seed(1235)
my_control = trainControl(method="cv", number=5)
Grid = expand.grid(alpha = 1, lambda = seq(0.001,0.1,by = 0.0002))

lasso_linear_reg_mod = train(x = train[, -c("Item_Identifier", "Item_Outlet_Sales")], y = train$Item_Outlet_Sales,
                             method='glmnet', trControl= my_control, tuneGrid = Grid)

lassoprediction = predict(lasso_linear_reg_mod, test[,-c("Item_Identifier","Item_Outlet_Sales")])

plot(lassoprediction[1:50],type="o",col = "red", xlab = "Values", ylab = "Sales", 
   main = "Line chart")
lines(actual[1:50], type = "o", col = "blue")
rmse(actual, lassoprediction)
```


```{r}
#Ridge Regression

set.seed(1236)
my_control = trainControl(method="cv", number=5)
Grid = expand.grid(alpha = 0, lambda = seq(0.001,0.1,by = 0.0002))

ridge_linear_reg_mod = train(x = train[, -c("Item_Identifier", "Item_Outlet_Sales")], y = train$Item_Outlet_Sales,
                             method='glmnet', trControl= my_control, tuneGrid = Grid)

ridgeprediction = predict(ridge_linear_reg_mod, test[,-c("Item_Identifier","Item_Outlet_Sales")])

plot(ridgeprediction[1:50],type="o",col = "red", xlab = "Values", ylab = "Sales", 
   main = "Line chart")
lines(actual[1:50], type = "o", col = "blue")

library(hydroGOF) #na.rm in rmse

rmse(actual, ridgeprediction,na.rm=TRUE)
```


```{r}
#RandomForest 

set.seed(1237)
my_control = trainControl(method="cv", number=5)

tgrid = expand.grid(
  .mtry = c(3:10),
  .splitrule = "variance",
  .min.node.size = c(10,15,20)
)

rf_mod = train(x = train[, -c("Item_Identifier", "Item_Outlet_Sales")], 
               y = train$Item_Outlet_Sales,
               method='ranger', 
               trControl= my_control, 
               tuneGrid = tgrid,
               num.trees = 100,
               importance = "permutation")

# mean validation score
mean(rf_mod$resample$RMSE)


#Best Model Parameters

plot(rf_mod)

#Variable Importance

plot(varImp(rf_mod))
```


```{r}

```


```{r}

test = test[complete.cases(test), ]
rfprediction = predict(rf_mod, test[,-c("Item_Identifier","Item_Outlet_Sales")])

plot(rfprediction[1:50],type="o",col = "red", xlab = "Values", ylab = "Sales", 
   main = "Line chart")
actual = test$Item_Outlet_Sales
lines(actual[1:50], type = "o", col = "blue")
rmse(actual, rfprediction)
```


```{r}
#XGBoost

param_list = list(
  
  objective = "reg:linear",
  eta=0.01,
  gamma = 1,
  max_depth=6,
  subsample=0.8,
  colsample_bytree=0.5
)
dtrain = xgb.DMatrix(data = as.matrix(train[,-c("Item_Identifier", "Item_Outlet_Sales")]), label= train$Item_Outlet_Sales)
dtest = xgb.DMatrix(data = as.matrix(test[,-c("Item_Identifier","Item_Outlet_Sales")]))

#Variable Importance

set.seed(112)
xgbcv = xgb.cv(params = param_list, 
               data = dtrain, 
               nrounds = 1000, 
               nfold = 5, 
               print_every_n = 10, 
               early_stopping_rounds = 30, 
               maximize = F)

#Model Training

xgb_model = xgb.train(data = dtrain, params = param_list, nrounds = 430)

#Variable Importance

var_imp = xgb.importance(feature_names = setdiff(names(train), c("Item_Identifier", "Item_Outlet_Sales")), 
                         model = xgb_model)
xgb.plot.importance(var_imp)
```


```{r}
xgb_model
```


```{r}

xgprediction = predict(xgb_model,dtest )

plot(xgprediction[1:50],type="o",col = "red", xlab = "Values", ylab = "Sales", 
   main = "Line chart")
lines(actual[1:50], type = "o", col = "blue")
rmse(actual, xgprediction)
```
```


```{r}











```